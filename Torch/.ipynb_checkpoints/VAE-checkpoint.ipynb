{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/in/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d00b0305e9f497ca8e01480e735d834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/in/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/in/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/in/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a877a00ee7c84ddca6821a2ac7638365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/in/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/in/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/in/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b23d486c0941f489d7cf7a76ee752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/in/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/in/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/in/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e4bd603d884b55a0631b9da2dc2b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/in/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/in/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinxu/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.MNIST(root='../../data/in',\n",
    "                                    train=True,\n",
    "                                    transform=transforms.ToTensor(),\n",
    "                                    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinxu/.local/lib/python3.6/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/kevinxu/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 36089.8516, KL Div: 3667.4338\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29914.4297, KL Div: 904.3251\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27311.5957, KL Div: 1230.7915\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26694.3770, KL Div: 629.2594\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 27225.7090, KL Div: 708.2644\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25336.0352, KL Div: 785.5221\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25095.7578, KL Div: 863.5602\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 24490.9883, KL Div: 976.2679\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23837.1094, KL Div: 1020.4596\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 22557.2734, KL Div: 1315.6624\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 21732.7930, KL Div: 1472.5048\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20458.5234, KL Div: 1691.8617\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 20765.3652, KL Div: 1741.7332\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19112.7422, KL Div: 1743.7903\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 18821.9102, KL Div: 1787.4368\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18318.4121, KL Div: 1729.2700\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18790.1523, KL Div: 1890.8699\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18335.6797, KL Div: 1914.3010\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 18503.6406, KL Div: 2008.0258\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 17945.4414, KL Div: 1933.7134\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17177.5684, KL Div: 2042.7599\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 16818.1816, KL Div: 2006.3328\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16767.2617, KL Div: 2135.1587\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16346.3672, KL Div: 2201.6216\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16938.6973, KL Div: 2060.9658\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16883.4844, KL Div: 2150.6638\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 15975.2617, KL Div: 2141.6987\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 15748.2295, KL Div: 2251.7764\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15329.4844, KL Div: 2336.9238\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15984.7930, KL Div: 2280.1677\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15248.3789, KL Div: 2375.6753\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15175.2285, KL Div: 2473.9658\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15374.9609, KL Div: 2548.7327\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 14377.4141, KL Div: 2322.8259\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14522.6270, KL Div: 2592.7305\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14679.4355, KL Div: 2383.1106\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14607.4141, KL Div: 2552.8340\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14896.8486, KL Div: 2458.9250\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14364.8193, KL Div: 2570.7891\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 13909.3730, KL Div: 2617.0864\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 13946.9258, KL Div: 2562.9058\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 13627.6016, KL Div: 2494.1118\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14272.4941, KL Div: 2587.2800\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 13549.4102, KL Div: 2733.5200\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 14048.8594, KL Div: 2622.1482\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13990.5078, KL Div: 2672.7546\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 12940.7539, KL Div: 2530.8989\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13908.8760, KL Div: 2637.7644\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 12809.0010, KL Div: 2566.5681\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13424.2441, KL Div: 2695.4414\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13479.0410, KL Div: 2698.3613\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13747.6562, KL Div: 2613.9963\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13617.3643, KL Div: 2812.7644\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13397.5088, KL Div: 2740.4612\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 12436.4600, KL Div: 2800.1885\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 12603.5137, KL Div: 2755.7334\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13137.3379, KL Div: 2766.3145\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13424.3984, KL Div: 2820.6060\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 12928.7432, KL Div: 2747.7661\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 12545.7295, KL Div: 2914.0991\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12899.5605, KL Div: 2741.7358\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 11886.1230, KL Div: 2827.0928\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 13115.6113, KL Div: 2839.5312\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12849.3887, KL Div: 2794.2368\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12887.2285, KL Div: 2921.5693\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 11726.5742, KL Div: 2821.0293\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12719.9912, KL Div: 2778.8955\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12800.6445, KL Div: 2819.3003\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12425.7832, KL Div: 2858.0422\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12343.0889, KL Div: 3016.8994\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12400.9746, KL Div: 2843.2437\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12442.9443, KL Div: 2970.2625\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12440.0684, KL Div: 2929.4414\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12669.1680, KL Div: 3070.2568\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 13547.7139, KL Div: 2813.4019\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12363.7324, KL Div: 2991.8381\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 11942.1748, KL Div: 2885.6914\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12470.3047, KL Div: 2956.1187\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12118.9189, KL Div: 2879.8450\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12426.5098, KL Div: 2968.3748\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12466.6104, KL Div: 2957.0127\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12010.7920, KL Div: 2983.3955\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 11970.5518, KL Div: 3057.6035\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 13261.4277, KL Div: 2977.6289\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 11812.2871, KL Div: 2923.1062\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 11941.6123, KL Div: 2881.6084\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 11814.6162, KL Div: 2972.6572\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12379.3418, KL Div: 2975.8359\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11445.1367, KL Div: 3055.0483\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 11959.2090, KL Div: 3027.2598\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12081.4814, KL Div: 3023.2783\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11988.9121, KL Div: 2927.4387\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11739.0264, KL Div: 2971.1008\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 11552.5791, KL Div: 2981.2852\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11386.7578, KL Div: 3048.0908\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11641.8408, KL Div: 3001.7732\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 12206.2227, KL Div: 2892.2871\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11981.5215, KL Div: 3003.5488\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11733.9912, KL Div: 2959.5591\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 11305.7725, KL Div: 2943.2305\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11846.8633, KL Div: 3155.2983\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 12041.0508, KL Div: 3035.2148\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11947.7812, KL Div: 3176.8137\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11796.7715, KL Div: 3066.8042\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11841.1855, KL Div: 3078.0898\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11218.0059, KL Div: 3089.4050\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11317.7451, KL Div: 2993.6482\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11783.7070, KL Div: 3178.2905\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11836.2891, KL Div: 3081.3599\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11764.1562, KL Div: 3068.6282\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11532.2734, KL Div: 3025.1975\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11370.3369, KL Div: 3022.7876\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11162.8965, KL Div: 2957.0205\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11689.5967, KL Div: 3181.6338\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11132.7666, KL Div: 3078.0356\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11282.5996, KL Div: 3083.0801\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11626.8633, KL Div: 3054.2769\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11152.9053, KL Div: 3103.0857\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11150.1172, KL Div: 3015.5618\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11158.7412, KL Div: 2999.9880\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11442.1113, KL Div: 3095.0291\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11388.1875, KL Div: 2985.6006\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11176.8203, KL Div: 3029.0825\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11146.6152, KL Div: 3041.4775\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11719.7031, KL Div: 2955.4463\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11517.3076, KL Div: 3067.1128\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11765.6250, KL Div: 3225.7527\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 10939.4248, KL Div: 3157.8799\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 10936.3604, KL Div: 2996.9688\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11984.4297, KL Div: 3016.3699\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11193.8008, KL Div: 3145.3296\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11420.1035, KL Div: 3047.1982\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11245.1201, KL Div: 3026.7278\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 10861.1025, KL Div: 3052.3508\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11238.7402, KL Div: 3035.5967\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11445.2393, KL Div: 3055.4170\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11405.6719, KL Div: 3195.9106\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11344.2432, KL Div: 3124.1665\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11585.5996, KL Div: 3246.7974\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11416.2246, KL Div: 3078.8784\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11404.8086, KL Div: 3314.4976\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11150.9219, KL Div: 3114.1453\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11022.6416, KL Div: 3135.9592\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11316.8359, KL Div: 3063.3411\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11318.0762, KL Div: 3081.2222\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11227.1172, KL Div: 3228.2510\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11835.0010, KL Div: 3130.6992\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10568.2617, KL Div: 3123.6077\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11410.3613, KL Div: 3049.3853\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11139.1016, KL Div: 3102.7478\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11353.9824, KL Div: 3197.4443\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11584.5850, KL Div: 3079.0854\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 10763.7461, KL Div: 3192.4688\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11137.0791, KL Div: 3055.5366\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11158.9492, KL Div: 3060.1797\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11171.9355, KL Div: 3173.7153\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11363.0771, KL Div: 3150.9590\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11896.7891, KL Div: 3252.2007\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11390.1670, KL Div: 3135.8574\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 10711.6582, KL Div: 3163.4541\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 11311.1816, KL Div: 3168.0098\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11626.7598, KL Div: 3153.9897\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 10505.7285, KL Div: 3104.1396\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11129.7119, KL Div: 3135.4067\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11185.7168, KL Div: 3042.5586\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 10939.0488, KL Div: 3155.8799\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 11565.5586, KL Div: 3264.7427\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11378.7090, KL Div: 2995.5933\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 10505.2529, KL Div: 3136.6770\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11113.3516, KL Div: 3169.3389\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11285.5527, KL Div: 3164.6851\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11045.7285, KL Div: 3100.0242\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11269.7656, KL Div: 3199.0303\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 11690.8535, KL Div: 3131.1714\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10793.4297, KL Div: 3232.8689\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11007.3203, KL Div: 3103.3315\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11286.2344, KL Div: 3180.5552\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11070.4014, KL Div: 3263.7485\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 11000.4307, KL Div: 3164.9294\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 11241.4590, KL Div: 3152.6924\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 11385.6055, KL Div: 3178.4404\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 11201.4277, KL Div: 3077.6030\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10676.5684, KL Div: 3138.4307\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 11138.4023, KL Div: 3201.4985\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10612.0723, KL Div: 3052.8110\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 11069.5723, KL Div: 3286.8284\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10613.7422, KL Div: 3062.2666\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 11155.5352, KL Div: 3219.9141\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10842.6016, KL Div: 3076.2910\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10643.7246, KL Div: 3206.5005\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11163.8105, KL Div: 3189.2046\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 10979.2461, KL Div: 3128.2344\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10929.8262, KL Div: 3134.1826\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10800.5840, KL Div: 3187.7332\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 10761.9180, KL Div: 3188.7109\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10391.4238, KL Div: 3105.5718\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10998.2695, KL Div: 3247.9751\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10543.0156, KL Div: 3061.6880\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 11017.3535, KL Div: 3248.5195\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 11005.6514, KL Div: 3057.2297\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 11453.1865, KL Div: 3306.3228\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11351.5684, KL Div: 3214.3464\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 10905.1826, KL Div: 3124.1201\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10375.0029, KL Div: 3141.3755\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 11124.6016, KL Div: 3057.7981\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10519.8750, KL Div: 3143.0391\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 11147.7197, KL Div: 3115.7224\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 10836.1172, KL Div: 3266.6719\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 11158.9512, KL Div: 3171.8174\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10920.3301, KL Div: 3184.4382\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 10623.1660, KL Div: 3134.2036\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10744.8086, KL Div: 3153.2192\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10808.0000, KL Div: 3164.6709\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 9830.4277, KL Div: 3130.6851\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10136.0186, KL Div: 3068.5210\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 11067.4326, KL Div: 3156.3293\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10668.7822, KL Div: 3244.0933\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10999.3633, KL Div: 3210.9773\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10416.0117, KL Div: 3083.4568\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 11394.2344, KL Div: 3130.2710\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10883.3330, KL Div: 3109.4009\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 11117.6104, KL Div: 3158.0107\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 11030.4785, KL Div: 3141.3120\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10147.0498, KL Div: 3098.1777\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10480.5039, KL Div: 3371.7534\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10671.6855, KL Div: 3188.7646\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10736.9268, KL Div: 3050.4382\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 11216.2031, KL Div: 3269.5015\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 11096.0039, KL Div: 3208.8291\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10854.9316, KL Div: 3163.1377\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10517.1299, KL Div: 3172.1709\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10900.9404, KL Div: 3165.7793\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10371.4961, KL Div: 3121.2710\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10590.3828, KL Div: 3186.5171\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 10703.1387, KL Div: 3066.4897\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10729.0176, KL Div: 3211.7041\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10371.7812, KL Div: 3111.0430\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10724.1641, KL Div: 3185.6602\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 11007.5000, KL Div: 3206.2068\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10364.1953, KL Div: 3175.5742\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10408.2793, KL Div: 3144.1208\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10767.5547, KL Div: 3114.2803\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 11150.2324, KL Div: 3251.6641\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10266.8750, KL Div: 3091.9800\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10509.2100, KL Div: 3196.6768\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10709.6152, KL Div: 3149.3906\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 11125.7734, KL Div: 3227.1260\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10513.2734, KL Div: 3219.2578\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 11105.6992, KL Div: 3298.8789\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10390.2305, KL Div: 3137.3750\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 11142.6748, KL Div: 3185.0103\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10606.7188, KL Div: 3147.1719\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10896.6699, KL Div: 3261.9131\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10847.7979, KL Div: 3329.5940\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 10772.7090, KL Div: 3162.3342\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10768.8350, KL Div: 3279.3516\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10762.5430, KL Div: 3139.6550\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10828.5811, KL Div: 3158.6816\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10265.9863, KL Div: 3150.4438\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10254.5889, KL Div: 3160.5884\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10734.8750, KL Div: 3123.8477\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10361.8418, KL Div: 3219.5249\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10928.3096, KL Div: 3217.7515\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10782.9297, KL Div: 3051.8838\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 11082.0635, KL Div: 3273.7898\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10753.3916, KL Div: 3163.2319\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10393.0020, KL Div: 3265.9307\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10712.8672, KL Div: 3059.5630\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10647.9941, KL Div: 3273.1704\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10720.2627, KL Div: 3113.6677\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 11181.8086, KL Div: 3282.1028\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10831.3418, KL Div: 3276.6792\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10480.0703, KL Div: 3165.1143\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10656.0840, KL Div: 3260.7178\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 11201.0332, KL Div: 3057.6572\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10598.2305, KL Div: 3228.8586\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10797.4414, KL Div: 3195.7544\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10610.1602, KL Div: 3250.9731\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10482.6445, KL Div: 3127.8120\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10557.3496, KL Div: 3227.9121\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10973.0859, KL Div: 3162.9705\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10543.8330, KL Div: 3209.4971\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10708.6768, KL Div: 3184.3496\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10194.3135, KL Div: 2996.2300\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10529.3359, KL Div: 3226.5139\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10642.7129, KL Div: 3145.2271\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10816.5732, KL Div: 3264.1609\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10418.1738, KL Div: 3063.2842\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10311.6250, KL Div: 3213.3066\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10542.5498, KL Div: 3157.1082\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10652.0918, KL Div: 3166.8330\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10621.9434, KL Div: 3156.1785\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10927.7969, KL Div: 3206.6790\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10529.5244, KL Div: 3214.3145\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10567.4678, KL Div: 3207.5251\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 11006.4180, KL Div: 3254.2935\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10902.3047, KL Div: 3221.1167\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 11158.7129, KL Div: 3217.1587\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10744.4131, KL Div: 3223.8594\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10737.3848, KL Div: 3061.8213\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10377.7861, KL Div: 3186.0706\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10004.2676, KL Div: 3054.0049\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10628.0820, KL Div: 3174.9587\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10688.9102, KL Div: 3328.4941\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 11108.2910, KL Div: 3284.3533\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10218.6680, KL Div: 3165.3987\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10308.3760, KL Div: 3127.5391\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10741.4268, KL Div: 3153.1099\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10635.9092, KL Div: 3274.4478\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10322.9834, KL Div: 3227.7202\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10744.7070, KL Div: 3180.2678\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10860.1855, KL Div: 3221.8418\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10352.4912, KL Div: 3177.0811\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10543.6445, KL Div: 3226.6873\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10130.3174, KL Div: 3228.3325\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10924.7627, KL Div: 3178.9746\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10338.6504, KL Div: 3221.5103\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10570.6445, KL Div: 3274.9929\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10289.4316, KL Div: 3150.3042\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10642.3457, KL Div: 3241.5696\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10337.0293, KL Div: 3066.5293\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10129.1855, KL Div: 3229.2290\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10658.3721, KL Div: 3115.8174\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10687.2393, KL Div: 3299.4241\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10747.1191, KL Div: 3230.5049\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10535.4102, KL Div: 3293.8511\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10630.6562, KL Div: 3136.2461\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10749.7012, KL Div: 3167.6921\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10632.2998, KL Div: 3203.4880\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10174.8203, KL Div: 3182.9604\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10750.2383, KL Div: 3261.7605\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10332.3398, KL Div: 3202.5623\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10314.2070, KL Div: 3351.4863\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10394.3828, KL Div: 3185.4919\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10684.9414, KL Div: 3316.2764\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10848.5977, KL Div: 3122.9712\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10415.0293, KL Div: 3214.5845\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10162.5771, KL Div: 3100.1753\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10770.4727, KL Div: 3184.1069\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10099.6426, KL Div: 3236.2849\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10591.6943, KL Div: 3182.1790\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10701.9170, KL Div: 3203.4399\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10515.7227, KL Div: 3204.6602\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10463.7969, KL Div: 3202.0942\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10262.4111, KL Div: 3211.8535\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10905.7617, KL Div: 3277.6687\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10723.5205, KL Div: 3241.6621\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10667.3135, KL Div: 3215.7268\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10485.7139, KL Div: 3146.6003\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10170.9902, KL Div: 3171.5557\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10812.6074, KL Div: 3234.2332\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10513.2578, KL Div: 3193.2595\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10583.0195, KL Div: 3288.0762\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10435.7422, KL Div: 3239.1938\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10512.7578, KL Div: 3280.6045\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10921.0898, KL Div: 3219.6914\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10267.3301, KL Div: 3142.5210\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10114.7061, KL Div: 3287.4375\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 9969.0605, KL Div: 3132.0063\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10424.8027, KL Div: 3169.5833\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10628.6836, KL Div: 3292.9031\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10787.8330, KL Div: 3196.4644\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 11147.9131, KL Div: 3339.2676\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10588.0098, KL Div: 3176.9575\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10685.9492, KL Div: 3293.5151\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10057.1914, KL Div: 3321.4961\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10896.3770, KL Div: 3241.0703\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10836.4434, KL Div: 3261.1494\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 11120.3672, KL Div: 3213.5552\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10276.2559, KL Div: 3226.6753\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10689.0879, KL Div: 3231.8765\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10559.4727, KL Div: 3164.5444\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 11053.4277, KL Div: 3242.3525\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10643.5156, KL Div: 3229.5049\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10144.3496, KL Div: 3200.2095\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10261.2656, KL Div: 3325.1099\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10714.0723, KL Div: 3281.3438\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10233.8975, KL Div: 3232.6812\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10346.3379, KL Div: 3248.2803\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10215.6816, KL Div: 3233.3494\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10832.1250, KL Div: 3179.3367\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10590.8379, KL Div: 3232.4109\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 9902.2832, KL Div: 3162.7219\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10407.1230, KL Div: 3185.3477\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10709.4893, KL Div: 3262.8904\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10477.5752, KL Div: 3154.0757\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10165.9199, KL Div: 3290.9463\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10280.9844, KL Div: 3167.0186\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10698.3984, KL Div: 3145.4199\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 11014.0352, KL Div: 3350.5664\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10197.2559, KL Div: 3213.1323\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10664.9570, KL Div: 3084.8555\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10231.5273, KL Div: 3325.6008\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10782.8643, KL Div: 3197.6692\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10590.2354, KL Div: 3301.8340\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10468.4902, KL Div: 3372.3352\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10274.3594, KL Div: 3156.4365\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10618.3281, KL Div: 3346.9561\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10663.5781, KL Div: 3237.6348\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10160.6133, KL Div: 3157.2092\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10352.5293, KL Div: 3195.7695\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10414.9160, KL Div: 3265.8589\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10226.8076, KL Div: 3118.4761\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10311.9102, KL Div: 3176.8545\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10084.7354, KL Div: 3323.3503\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10909.6807, KL Div: 3174.5024\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10018.5352, KL Div: 3265.3594\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10171.1104, KL Div: 3156.6873\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10595.7363, KL Div: 3156.8916\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 9870.6426, KL Div: 3189.6277\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10171.4043, KL Div: 3169.2339\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10719.7695, KL Div: 3264.7314\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10461.5869, KL Div: 3175.6440\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10371.9336, KL Div: 3358.1030\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10701.4141, KL Div: 3259.7344\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10654.5977, KL Div: 3242.2649\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10590.9922, KL Div: 3288.8171\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10155.2109, KL Div: 3124.5889\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10650.3535, KL Div: 3266.9966\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10368.6045, KL Div: 3209.7327\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10356.7559, KL Div: 3122.5068\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10568.7910, KL Div: 3289.7185\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10328.3955, KL Div: 3242.1523\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 9995.9287, KL Div: 3049.1104\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10408.6270, KL Div: 3214.0146\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10277.8730, KL Div: 3241.4092\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10121.6777, KL Div: 3089.1235\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10581.9336, KL Div: 3327.7236\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10543.4121, KL Div: 3216.3833\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10049.1611, KL Div: 3145.9746\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10215.1670, KL Div: 3312.7480\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10480.4541, KL Div: 3133.6025\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10274.2266, KL Div: 3304.9619\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10035.2773, KL Div: 3212.8613\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10509.2344, KL Div: 3216.7039\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10517.8359, KL Div: 3343.7197\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10356.8027, KL Div: 3168.7622\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10288.6816, KL Div: 3176.4038\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 9945.8594, KL Div: 3157.4189\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10569.0098, KL Div: 3269.1719\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 9841.7617, KL Div: 3160.6826\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 9801.2051, KL Div: 3211.7720\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10401.0615, KL Div: 3265.3894\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10289.9863, KL Div: 3162.8247\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10323.8125, KL Div: 3261.3057\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10409.9570, KL Div: 3266.2161\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10028.1846, KL Div: 3062.6279\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10324.1953, KL Div: 3342.3066\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10488.0322, KL Div: 3282.4519\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10360.9160, KL Div: 3274.4480\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10368.1494, KL Div: 3278.0713\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10332.3262, KL Div: 3219.2109\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10328.3213, KL Div: 3241.3242\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10132.9229, KL Div: 3140.7441\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 9831.9062, KL Div: 3107.3616\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10353.3926, KL Div: 3281.6055\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10361.6387, KL Div: 3160.1252\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10453.6660, KL Div: 3272.0222\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10557.0703, KL Div: 3226.7720\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10404.9316, KL Div: 3215.5913\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10183.0000, KL Div: 3199.0725\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 9975.7168, KL Div: 3266.4648\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10117.1250, KL Div: 3086.7896\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10780.8516, KL Div: 3221.3606\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10541.7188, KL Div: 3347.0596\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10396.1797, KL Div: 3271.4727\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10139.7197, KL Div: 3178.3496\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 9933.7041, KL Div: 3189.8228\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10452.2969, KL Div: 3317.2329\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 9823.8965, KL Div: 3116.9204\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10468.9062, KL Div: 3236.2263\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10604.9980, KL Div: 3224.5530\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10419.5332, KL Div: 3276.0879\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10647.8262, KL Div: 3333.8384\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10551.0322, KL Div: 3154.4722\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 9868.4297, KL Div: 3264.7092\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10436.6318, KL Div: 3150.6138\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10165.6680, KL Div: 3133.8149\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10517.3555, KL Div: 3201.3000\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10110.5420, KL Div: 3227.0212\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10595.4775, KL Div: 3222.1550\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10181.3135, KL Div: 3350.3413\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10735.1875, KL Div: 3357.1470\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10696.7344, KL Div: 3211.7808\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10181.3750, KL Div: 3169.4363\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 10092.0850, KL Div: 3278.5481\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10580.5352, KL Div: 3254.0828\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10396.4902, KL Div: 3248.6123\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 9936.6758, KL Div: 3255.5181\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10400.4258, KL Div: 3100.9922\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10071.0742, KL Div: 3222.3105\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10184.5713, KL Div: 3309.0708\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 9611.9990, KL Div: 3154.9209\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10062.0225, KL Div: 3199.0371\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10138.1973, KL Div: 3174.2312\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10174.8760, KL Div: 3241.1836\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10366.2471, KL Div: 3176.3340\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 9884.5635, KL Div: 3252.9995\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10330.9121, KL Div: 3311.6406\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10057.1406, KL Div: 3200.3665\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10077.6943, KL Div: 3197.4395\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10430.4375, KL Div: 3248.2471\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10367.5527, KL Div: 3154.3938\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 9930.4551, KL Div: 3300.5693\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10086.4473, KL Div: 3173.5132\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10337.5117, KL Div: 3209.1011\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10267.0820, KL Div: 3099.8530\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10144.1035, KL Div: 3134.3577\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10561.7285, KL Div: 3315.9727\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10280.0947, KL Div: 3221.6250\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10435.6035, KL Div: 3237.5789\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10128.6289, KL Div: 3199.5767\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10123.4004, KL Div: 3181.3535\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10073.9521, KL Div: 3186.0276\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10041.8184, KL Div: 3191.9988\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10429.6875, KL Div: 3197.2832\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10472.1191, KL Div: 3316.3572\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10796.0527, KL Div: 3170.2231\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10155.8496, KL Div: 3156.2778\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 9945.9492, KL Div: 3258.7212\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10159.3291, KL Div: 3100.4719\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10263.4824, KL Div: 3282.7681\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10436.1484, KL Div: 3203.8467\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10332.6367, KL Div: 3268.7065\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10015.1162, KL Div: 3230.1919\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10170.5107, KL Div: 3205.3228\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 9770.5352, KL Div: 3260.8269\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10261.0703, KL Div: 3276.2441\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10702.6885, KL Div: 3260.7524\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10329.6426, KL Div: 3271.2324\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 9797.3682, KL Div: 3164.5146\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10379.9473, KL Div: 3227.5430\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10110.3896, KL Div: 3260.2231\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10594.7617, KL Div: 3216.9492\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10599.7012, KL Div: 3242.7043\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10004.1250, KL Div: 3224.8188\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10782.1182, KL Div: 3239.9053\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10456.4443, KL Div: 3266.9954\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10122.5371, KL Div: 3242.6802\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10388.7646, KL Div: 3256.6968\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 9946.1367, KL Div: 3222.3870\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10878.3281, KL Div: 3306.0872\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10345.6191, KL Div: 3172.9824\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10877.9355, KL Div: 3368.7822\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10308.7344, KL Div: 3157.5396\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10385.0635, KL Div: 3214.7783\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10159.0000, KL Div: 3364.5916\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10302.7480, KL Div: 3137.5942\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10188.9727, KL Div: 3254.3506\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10368.4932, KL Div: 3238.3853\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10611.3584, KL Div: 3297.1218\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10152.2471, KL Div: 3253.8325\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10691.5605, KL Div: 3297.8257\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10205.5820, KL Div: 3301.0764\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10604.8809, KL Div: 3320.9480\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10267.3457, KL Div: 3324.8655\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10077.4482, KL Div: 3213.2683\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10058.8984, KL Div: 3297.8066\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10076.8779, KL Div: 3148.6362\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10038.8848, KL Div: 3192.0046\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10479.8398, KL Div: 3270.8416\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10148.7773, KL Div: 3299.6729\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10492.2676, KL Div: 3223.0308\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10190.9102, KL Div: 3222.6475\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10396.1270, KL Div: 3285.5508\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10193.1309, KL Div: 3185.3862\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10793.9434, KL Div: 3251.9243\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10015.9629, KL Div: 3236.4158\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 9937.4453, KL Div: 3106.9209\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10403.0527, KL Div: 3243.4905\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10119.1201, KL Div: 3210.8369\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10668.0039, KL Div: 3371.6143\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10167.9961, KL Div: 3084.0815\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 9936.5391, KL Div: 3236.6099\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10163.9590, KL Div: 3187.5664\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10368.9824, KL Div: 3289.3274\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10178.0459, KL Div: 3255.6340\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10065.4492, KL Div: 3187.8208\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10297.4746, KL Div: 3330.3862\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10223.7930, KL Div: 3263.8042\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10298.1572, KL Div: 3261.3159\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 9720.1543, KL Div: 3166.0503\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10475.8037, KL Div: 3247.6982\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10383.2148, KL Div: 3309.6279\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10532.1152, KL Div: 3343.5320\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10271.0234, KL Div: 3236.7397\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10585.2627, KL Div: 3351.2310\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10124.5996, KL Div: 3273.5210\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10409.8828, KL Div: 3196.7266\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10413.3613, KL Div: 3254.1257\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10113.1328, KL Div: 3271.9136\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10538.3984, KL Div: 3206.6838\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10210.1895, KL Div: 3250.8530\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10282.3145, KL Div: 3295.3760\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10685.9971, KL Div: 3254.4001\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10071.8984, KL Div: 3171.3022\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10056.9688, KL Div: 3160.5554\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10218.7559, KL Div: 3245.6296\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10258.5088, KL Div: 3253.6426\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10181.1680, KL Div: 3252.8164\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10005.9307, KL Div: 3135.8303\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10870.3838, KL Div: 3335.3699\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10203.1719, KL Div: 3235.6572\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 9854.3066, KL Div: 3223.6094\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 9874.2773, KL Div: 3243.7759\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10276.5967, KL Div: 3319.0972\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10592.9141, KL Div: 3248.6602\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 9902.5361, KL Div: 3165.3528\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10089.2617, KL Div: 3261.5664\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10145.2168, KL Div: 3225.8435\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10019.2637, KL Div: 3153.4502\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 9793.1387, KL Div: 3272.1016\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 9531.7207, KL Div: 3222.9910\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10203.4717, KL Div: 3244.5713\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 9916.7725, KL Div: 3211.6255\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10134.7510, KL Div: 3206.6243\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10287.4873, KL Div: 3288.1711\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10384.9541, KL Div: 3308.7490\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10184.4551, KL Div: 3184.2632\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10280.4102, KL Div: 3315.9849\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10078.1230, KL Div: 3098.0342\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10144.9277, KL Div: 3269.5859\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10110.8193, KL Div: 3225.7539\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 9754.8945, KL Div: 3246.7747\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10240.8447, KL Div: 3265.4746\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10491.9902, KL Div: 3214.0818\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10420.8633, KL Div: 3248.0049\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10012.8984, KL Div: 3352.5029\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10103.2227, KL Div: 3231.2668\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 9818.7314, KL Div: 3155.0962\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10407.5176, KL Div: 3246.6438\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10447.9268, KL Div: 3382.5781\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10285.5283, KL Div: 3232.7468\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10577.7969, KL Div: 3174.5652\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10124.3066, KL Div: 3218.0815\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10263.9707, KL Div: 3186.5691\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10262.5713, KL Div: 3246.4414\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10507.7012, KL Div: 3350.5344\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10339.8818, KL Div: 3240.2222\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10104.0645, KL Div: 3217.6780\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 9787.5684, KL Div: 3280.9507\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10211.3252, KL Div: 3312.0151\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10511.4678, KL Div: 3313.3828\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10501.4287, KL Div: 3210.4844\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10073.1553, KL Div: 3258.6238\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10077.3047, KL Div: 3206.9521\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10469.9922, KL Div: 3346.8010\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10269.7988, KL Div: 3159.5901\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10169.8184, KL Div: 3274.6899\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10333.5146, KL Div: 3173.9067\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10829.8281, KL Div: 3278.7808\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10054.8008, KL Div: 3330.0083\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 10226.1543, KL Div: 3194.9634\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 9877.7754, KL Div: 3248.1309\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10028.9912, KL Div: 3163.3950\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10635.6426, KL Div: 3289.4092\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10080.4883, KL Div: 3167.5190\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 9918.4697, KL Div: 3375.4675\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10072.8809, KL Div: 3118.3774\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 9970.3232, KL Div: 3167.2417\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10129.3750, KL Div: 3286.8970\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10228.0547, KL Div: 3143.9194\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10201.2070, KL Div: 3212.6392\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 9837.7588, KL Div: 3272.3691\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10281.0469, KL Div: 3249.8525\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10427.6533, KL Div: 3228.0217\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10128.8633, KL Div: 3394.2798\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 9937.6240, KL Div: 3209.0518\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10033.9316, KL Div: 3170.6130\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 9831.1768, KL Div: 3408.0986\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10523.6387, KL Div: 3166.5818\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10434.7441, KL Div: 3342.3413\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10003.2930, KL Div: 3145.1099\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10154.2227, KL Div: 3241.5630\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10010.3379, KL Div: 3226.0962\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10419.1240, KL Div: 3214.2661\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 9749.9941, KL Div: 3170.5947\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10447.8877, KL Div: 3184.5054\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10244.2832, KL Div: 3250.8940\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10036.4629, KL Div: 3137.1348\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 9783.3330, KL Div: 3254.6301\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10273.9121, KL Div: 3259.5820\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10339.5234, KL Div: 3237.7515\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10163.2285, KL Div: 3127.8989\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10347.5488, KL Div: 3253.1951\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 9977.1797, KL Div: 3100.8057\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 9723.9863, KL Div: 3216.2205\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10196.5547, KL Div: 3271.8389\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10113.8594, KL Div: 3211.2942\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 9835.8477, KL Div: 3242.4170\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and KL divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimise\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), \n",
    "                           reconst_loss.item(), kl_div.item()))\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "        \n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
